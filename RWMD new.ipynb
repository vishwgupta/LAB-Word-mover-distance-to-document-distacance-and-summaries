{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pyemd import emd\n",
    "import numpy as np\n",
    "from gensim import models\n",
    "from gensim.models import word2vec\n",
    "import numpy.linalg as la\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import scipy.spatial as spt\n",
    "from scipy.spatial import distance\n",
    "from pyemd import emd\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from numpy import dot, zeros, dtype, array, sqrt,double,array,sqrt, sum as np_sum\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vec = None\n",
    "array = None\n",
    "global words_1\n",
    "global words_2\n",
    "global words_1_set\n",
    "global words_2_set\n",
    "removed_words = ['sdkls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = np.memmap(\"data/embed.dat\", dtype=np.double, mode=\"r\", shape=(3000000, 300))\n",
    "with open(\"data/embed.vocab\") as f:\n",
    "    vocab_list = map(str.strip, f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_dict = {w: k for k, w in enumerate(vocab_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FileOpen(file1,file2):  \n",
    "    global woduplicates\n",
    "    woduplicates = None\n",
    "    with open(file1) as f:\n",
    "        global words_1\n",
    "        global words_1_set\n",
    "        words_1 = f.read().split()\n",
    "        words_1 = [token for token in words_1 if token in vocab_dict.keys()]\n",
    "        words_1_set = set(words_1)\n",
    "    woduplicates = None\n",
    "    with open(file2) as f:\n",
    "        global words_2\n",
    "        global words_2_set\n",
    "        words_2 = f.read().split()\n",
    "        words_2 = [token for token in words_2 if token in vocab_dict.keys()]\n",
    "        words_2_set = set(words_2)\n",
    "    #print(woduplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Dictionaty2Files(content, words):\n",
    "    doc_len = len(content)\n",
    "    d = []\n",
    "    for i, t in enumerate(words):\n",
    "        d.append(content.count(t) / float(doc_len))\n",
    "    return d   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_files(dir):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            r.append(os.path.join(root, name))\n",
    "    numberOfFiles = len(r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join(os.path.expanduser('.'),'data','dataWMD20NEWS','docs')\n",
    "fnames = list_files(path)\n",
    "numberOfFiles = len(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_matrix():\n",
    "    len1 = len(words_1_set)\n",
    "    len2 = len(words_2_set)\n",
    "    T = zeros((len1, len2), dtype=float)\n",
    "    distance = zeros((len1, len2), dtype=float)\n",
    "    for i, t1 in enumerate(words_1_set):\n",
    "        for j, t2 in enumerate(words_2_set):\n",
    "            distance[i][j] = sqrt(np_sum((W[[vocab_dict[t1]]] - W[[vocab_dict[t2]]])**2))\n",
    "        minimum = np.argmin(distance[i])\n",
    "        T[i,minimum] = d1[i]*distance[i][minimum]\n",
    "    sum1 = T.sum()\n",
    "  \n",
    "    T = zeros((len2, len1), dtype=float)\n",
    "    distance = zeros((len2, len1), dtype=float)\n",
    "    for i, t1 in enumerate(words_2_set):\n",
    "        for j, t2 in enumerate(words_1_set):\n",
    "            distance[i][j] = sqrt(np_sum((W[[vocab_dict[t1]]] - W[[vocab_dict[t2]]])**2))\n",
    "        minimum = np.argmin(distance[i])\n",
    "        T[i,minimum] = d1[j]*distance[i][minimum]\n",
    "    \n",
    "    sum2 = T.sum()\n",
    "    return max(sum1,sum2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter query document path: /home/vishwani/Downloads/LAB/FINALsubmissionSVEN/data/dataWMD20NEWS/testdata/querydoc\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "queryDocument = input(\"Please enter query document path: \")\n",
    "k=30\n",
    "RWMD_DICT = dict()\n",
    "filename1 = queryDocument\n",
    "fnames = list_files(path)\n",
    "numberFiles = len(fnames)\n",
    "for filename2 in fnames:\n",
    "    global woduplicates\n",
    "    FileOpen(filename1,filename2)\n",
    "    if((len(words_1)!=0)and len(words_2)!=0):\n",
    "        d1 = np.array(Dictionaty2Files(words_1, words_1_set), dtype=double)\n",
    "        d2 = np.array(Dictionaty2Files(words_2, words_2_set), dtype=double)\n",
    "        distance = distance_matrix()\n",
    "        RWMD_DICT.update({(filename2, distance)})\n",
    "    else:\n",
    "        print(\"skipped\")\n",
    "        print(filename2)\n",
    "sorted_RWMD = (sorted(RWMD_DICT.items(), key=lambda x:x[1]))\n",
    "k = 30\n",
    "sorted_RWMD_array = np.asarray(sorted_RWMD[0:k])\n",
    "print(sorted_RWMD_array)\n",
    "end = time.time()\n",
    "print((end-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_RWMD = (sorted(RWMD_DICT.items(), key=lambda x:x[1]))\n",
    "k = 30\n",
    "sorted_RWMD_array = np.asarray(sorted_RWMD[0:k])\n",
    "print(sorted_RWMD_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
