{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pyemd import emd\n",
    "import numpy as np\n",
    "from gensim import models\n",
    "from gensim.models import word2vec\n",
    "import numpy.linalg as la\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import scipy.spatial as spt\n",
    "from scipy.spatial import distance\n",
    "from pyemd import emd\n",
    "from sklearn.metrics import euclidean_distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vec = None\n",
    "array = None\n",
    "filename1 = 'data/dataWMD/1'\n",
    "filename2 = 'data/dataWMD/2'\n",
    "filename3 = 'data/dataWMD/3'\n",
    "removed_words = ['sdkls']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = np.memmap(\"data/embed.dat\", dtype=np.double, mode=\"r\", shape=(3000000, 300))\n",
    "with open(\"data/embed.vocab\") as f:\n",
    "    vocab_list = map(str.strip, f.readlines())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_dict = {w: k for k, w in enumerate(vocab_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(d, target=1.0):\n",
    "    raw = sum(d.values())\n",
    "    factor = target/raw\n",
    "    return {key:value* factor for key,value in d.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(filename1) as f:\n",
    "    words_1 = f.read().split()\n",
    "    woduplicates = set(words_1)\n",
    "with open(filename2) as f:\n",
    "    words_2 = f.read().split()\n",
    "    woduplicates = woduplicates.union(words_2)\n",
    "\n",
    "with open(filename3) as f:\n",
    "    words_3 = f.read().split()\n",
    "    woduplicates = woduplicates.union(words_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make a matrix of vectors of all the words\n",
    "def vectors_words(woduplicates):\n",
    "    word_vec = None\n",
    "    for item in woduplicates:\n",
    "        try:\n",
    "            vec = W[[vocab_dict[item]]]\n",
    "            vec = np.array(vec)\n",
    "            if word_vec is None:\n",
    "                word_vec = vec\n",
    "            else:\n",
    "                word_vec = np.vstack((word_vec, vec))\n",
    "        except KeyError as e:\n",
    "            global removed_words\n",
    "            removed_words += [item]\n",
    "            pass\n",
    "    return word_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_squared_EDM_method5(X):\n",
    "    D_ = euclidean_distances(X)\n",
    "    return D_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict_array(d):\n",
    "    global array\n",
    "    array = None\n",
    "    for key,value in d.items():\n",
    "        value = np.array(value)\n",
    "        if array is None:\n",
    "            array = value\n",
    "        else:\n",
    "            array = np.vstack((array, value))\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "word_vec = vectors_words(woduplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectors_words(woduplicates)\n",
    "remove = set(removed_words)\n",
    "woduplicates = woduplicates-remove\n",
    "\n",
    "dict_1 = dict.fromkeys(woduplicates, 0)\n",
    "dict_2 = dict.fromkeys(woduplicates, 0)\n",
    "dict_3 = dict.fromkeys(woduplicates, 0)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gave': 0, 'concert': 0, 'greets': 0, 'Illinois': 1, 'Obama': 1, 'speaks': 1, 'media': 1, 'Japan': 0, 'press': 0, 'President': 0, 'Chicago': 0, 'band': 0}\n",
      "{'gave': 0, 'concert': 0, 'greets': 1, 'Illinois': 0, 'Obama': 0, 'speaks': 0, 'media': 0, 'Japan': 0, 'press': 1, 'President': 1, 'Chicago': 1, 'band': 0}\n",
      "<<<>>>>>>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file1=open(filename1,\"r+\")\n",
    "for word in file1.read().split():\n",
    "    if word in dict_1:\n",
    "        dict_1[word] += 1\n",
    "print(dict_1)\n",
    "dict_1 = normalize(dict_1)\n",
    "file2=open(filename2,\"r+\")\n",
    "for word in file2.read().split():\n",
    "    if word in dict_2:\n",
    "        dict_2[word] += 1\n",
    "print(dict_2)\n",
    "dict_2 = normalize(dict_2)\n",
    "print(\"<<<>>>>>>\")\n",
    "file3=open(filename3,\"r+\")\n",
    "for word in file3.read().split():\n",
    "    if word in dict_3:\n",
    "        dict_3[word] += 1\n",
    "dict_3 = normalize(dict_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 12)\n"
     ]
    }
   ],
   "source": [
    "distance_matrix = compute_squared_EDM_method5(word_vec).astype(np.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d1 = np.squeeze(dict_array(dict_1)).astype(np.double)\n",
    "d2 = np.squeeze(dict_array(dict_2)).astype(np.double)\n",
    "d3 = np.squeeze(dict_array(dict_3)).astype(np.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between d1 and d2\n",
      "0.9857075171118326\n",
      "distance between d1 and d3\n",
      "1.3404909716651137\n"
     ]
    }
   ],
   "source": [
    "print(\"distance between d1 and d2\")\n",
    "print (emd(d2,d1,distance_matrix))\n",
    "print(\"distance between d1 and d3\")\n",
    "print (emd(d1,d3,distance_matrix))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
